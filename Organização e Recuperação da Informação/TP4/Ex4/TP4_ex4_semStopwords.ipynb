{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d7c3b401",
      "metadata": {
        "id": "d7c3b401"
      },
      "source": [
        "- Usaremos diversas bibliotecas: nltk, pandas e scikit-learn\n",
        "- Lembre se que algumas bibliotecas devem ser instaladas!\n",
        "- Usei \"pip install *nome da biblioteca*\" pra fazer a instalação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "74bb0b3d",
      "metadata": {
        "id": "74bb0b3d"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "914b1a3d",
      "metadata": {
        "id": "914b1a3d"
      },
      "outputs": [],
      "source": [
        "# Ler o arquivo com os dados, mostre uma amostra do arquivo e exibe a\n",
        "# contagem de cada uma das colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1e1c737e",
      "metadata": {
        "scrolled": true,
        "id": "1e1c737e"
      },
      "outputs": [],
      "source": [
        "#dataset = pd.read_csv('/Users/rodrigomiani/Dropbox/Trabalho/UFU/Disciplinas/Organização e Recuperação da Informação/Exercícios/TP/TP4/Tweets_Mg.csv',encoding='utf-8')\n",
        "dataset = pd.read_csv('Tweets_Mg.csv', encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b55e7708",
      "metadata": {
        "id": "b55e7708"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8f2856",
      "metadata": {
        "scrolled": true,
        "id": "4d8f2856"
      },
      "outputs": [],
      "source": [
        "dataset.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bcc884d",
      "metadata": {
        "id": "6bcc884d"
      },
      "outputs": [],
      "source": [
        "# Vamos contar quantos tweets de cada tipo existem: neutro, positivo e negativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d0cba1",
      "metadata": {
        "id": "28d0cba1"
      },
      "outputs": [],
      "source": [
        "dataset[dataset.Classificacao=='Neutro'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8854caf7",
      "metadata": {
        "id": "8854caf7"
      },
      "outputs": [],
      "source": [
        "dataset[dataset.Classificacao=='Positivo'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcbbe830",
      "metadata": {
        "id": "dcbbe830"
      },
      "outputs": [],
      "source": [
        "dataset[dataset.Classificacao=='Negativo'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63384d56",
      "metadata": {
        "id": "63384d56"
      },
      "outputs": [],
      "source": [
        "# Precisamos criar váriaveis diferentes para armazenar os tweets e a sua classificação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "4e483345",
      "metadata": {
        "id": "4e483345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c03db7-d542-477a-c45a-bc5cdc046045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "tweets_normal = dataset['Text'].values\n",
        "classes = dataset['Classificacao'].values\n",
        "\n",
        "\n",
        "tweets = []\n",
        "for tweet in tweets_normal:\n",
        "    palavras = tweet.lower().split()\n",
        "    filtrar_palavras= [w for w in palavras if w not in stopwords]\n",
        "    tweet_pronto = ' '.join(filtrar_palavras)\n",
        "    tweets.append(tweet_pronto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a617a9c",
      "metadata": {
        "id": "8a617a9c"
      },
      "outputs": [],
      "source": [
        "# Vamos treinar o nosso primeiro modelo de classificação de texto.\n",
        "# Algumas coisas são importantes aqui:\n",
        "\n",
        "# 1) Precisamos definir como representar os tweets (BoW)\n",
        "# 2) Precisamos definir qual algoritmo de classificação será usado\n",
        "\n",
        "\n",
        "### Breve explicação sobre o funcionamento de algoritmos de classificação: ###\n",
        "# O algoritmo irá relacionar o conteúdo da BoW (1,0,2,0,1) com a respectiva classificação 'Neutro'. Usando diferentes critérios e com auxílio dos dados\n",
        "# analisados, o algoritmo irá criar \"regras\" para identificar/generalizar cada uma das classificações - Neutro, Positivo e Negativo. Chamamos esse conjunto de regras de \"modelo\".\n",
        "# Feito isso, quando o modelo receber um novo tweet (BoW) sem a classificação, com base nas regras que foram criadas, ele irá tentar \"adivinhar\" qual será a classe daquele tweet.\n",
        "# ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e47cfc4b",
      "metadata": {
        "id": "e47cfc4b"
      },
      "outputs": [],
      "source": [
        "# Para resolver o problema 1), vamos usar somente o TF - CountVectorizer. Essa função já limpa aqueles caracteres esquisitos que vimos lá em cima.\n",
        "\n",
        "# Na linha 1, criamos um objeto do tipo CountVectorizer chamado vectorizer. Após isso, na linha 2, usamos o objeto vectorizer para calcular a frequência de todas as palavras da lista de tweets e armazenamos seu retorno em freq_tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "48a4a470",
      "metadata": {
        "id": "48a4a470"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(analyzer=\"word\")\n",
        "freq_tweets = vectorizer.fit_transform(tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a51203",
      "metadata": {
        "id": "04a51203"
      },
      "outputs": [],
      "source": [
        "# Para resolver o problema 2), vamos trabalhar com um algoritmo de classificação chamado de Naive Bayes. Ele é baseado em probabilidades.\n",
        "# Na linha 1, criamos um objeto chamado modelo do tipo Naive Bayes Multinomial.\n",
        "# Na linha 2, treinamos o modelo usando a frequência de palavras (freq_tweets) e as classes de cada instância."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "1ad03d89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "1ad03d89",
        "outputId": "b9e181c6-d2e9-41fb-a9de-ba46a76f2707"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "modelo = MultinomialNB()\n",
        "modelo.fit(freq_tweets,classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f234f0c3",
      "metadata": {
        "id": "f234f0c3"
      },
      "outputs": [],
      "source": [
        "# Vamos fazer alguns testes \"manuais\". Ou seja, fornecer como entrada para o modelo alguns tweets\n",
        "# e deixar que ele faça a classificação. Na opinião de vocês, qual seria a classificação para cada um desses\n",
        "# tweets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "0e9eff4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e9eff4a",
        "outputId": "784fc92d-d35d-4895-e8fd-246f8ce66207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O governo de Minas é uma tragédia, muito ruim', 'Estou muito feliz com o governo de Minas esse ano', 'O estado de Minas Gerais decretou calamidade financeira!!!', 'A segurança do estado está deixando a desejar', 'O governador de Minas é do Novo']\n"
          ]
        }
      ],
      "source": [
        "testes = ['O governo de Minas é uma tragédia, muito ruim','Estou muito feliz com o governo de Minas esse ano','O estado de Minas Gerais decretou calamidade financeira!!!','A segurança do estado está deixando a desejar','O governador de Minas é do Novo']\n",
        "print(testes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef3d94c",
      "metadata": {
        "id": "1ef3d94c"
      },
      "outputs": [],
      "source": [
        "# Calculo a BoW dos tweets dentro da variável testes usando o TF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "91834942",
      "metadata": {
        "id": "91834942"
      },
      "outputs": [],
      "source": [
        "freq_testes = vectorizer.transform(testes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a96e68a",
      "metadata": {
        "id": "9a96e68a"
      },
      "outputs": [],
      "source": [
        "# Faço a classificação dos tweets de testes usando o modelo treinado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "c6aa94e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6aa94e6",
        "outputId": "44ba8b39-1609-44f0-b250-b79e35db840d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Negativo', 'Neutro', 'Negativo', 'Neutro', 'Neutro'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "modelo.predict(freq_testes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7a21c4",
      "metadata": {
        "id": "0d7a21c4"
      },
      "outputs": [],
      "source": [
        "# Vimos que o modelo funciona! Tem alguns erros mas isso faz parte do processo.\n",
        "# O próximo passo agora é fazer uma avaliação mais robusta do modelo.\n",
        "# Vamos usar uma parte da base de dados para treinar e a outra parte para testar.\n",
        "# Uma maneira de se fazer isso é usando um método chamado de \"Cross Validation\" ou \"Validação cruzada\".\n",
        "# Essta técnica consiste em dividir todo o conjunto de dados em K partes, que serão chamadas de folds.\n",
        "# Dessas partes, uma será separada para teste e as outras restantes serão usadas para treinar o modelo.\n",
        "\n",
        "## Exemplo ##\n",
        "\n",
        "# Para k = 10 , imagine que todo nosso dado de treino foi dividido em 10 partes distintas.\n",
        "# Assim, o modelo será treinado com 9 partes, e testado com a parte restante. Esse processo é repetido até que o modelo seja treinado e testado com todas as partes do dado.\n",
        "\n",
        "# A variável \"resultados\" guarda as previsões feitas pelo pelo modelo usando a validação cruzada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "aa087b95",
      "metadata": {
        "id": "aa087b95"
      },
      "outputs": [],
      "source": [
        "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd92bcc3",
      "metadata": {
        "id": "fd92bcc3"
      },
      "outputs": [],
      "source": [
        "# Pronto! Modelo treinado e validado! Como descobrir o desempenho do modelo? Inicialmente, usaremos uma\n",
        "# medida chamada de Acurácia que nada mais é do que o percentual de acertos que o modelo teve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "9643173b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9643173b",
        "outputId": "594753c1-808b-46b4-dc7f-40960f64722f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8771801439199902"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "metrics.accuracy_score(classes,resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "011a5f5c",
      "metadata": {
        "id": "011a5f5c"
      },
      "outputs": [],
      "source": [
        "# E se eu quiser saber o desempenho por cada uma das classes? Talvez o modelo acerte mais uma classe\n",
        "# do que a outra..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "0d8e0631",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d8e0631",
        "outputId": "757cfe15-6870-4a05-907a-6b2f0897c01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativo       0.88      0.92      0.90      2446\n",
            "      Neutro       0.79      0.84      0.81      2453\n",
            "    Positivo       0.95      0.87      0.91      3300\n",
            "\n",
            "    accuracy                           0.88      8199\n",
            "   macro avg       0.87      0.88      0.87      8199\n",
            "weighted avg       0.88      0.88      0.88      8199\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(metrics.classification_report(classes,resultados))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "622d6acc",
      "metadata": {
        "id": "622d6acc"
      },
      "outputs": [],
      "source": [
        "# E seu eu quiser saber a quantidade de acertos por classe? Nesse caso precisamos mostrar\n",
        "# a matriz de confusão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "570242f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "570242f7",
        "outputId": "846b0e60-d7bc-4004-add0-63d1ef2da16a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predito   Negativo  Neutro  Positivo   All\n",
            "Real                                      \n",
            "Negativo      2248     189         9  2446\n",
            "Neutro         249    2058       146  2453\n",
            "Positivo        47     367      2886  3300\n",
            "All           2544    2614      3041  8199\n"
          ]
        }
      ],
      "source": [
        "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ab8495",
      "metadata": {
        "id": "63ab8495"
      },
      "outputs": [],
      "source": [
        "# E aí? Terminou? Satisfeito com os resultados? Será que não dá pra melhorar?\n",
        "# Um primeiro ponto seria alterar a BoW. Uma outra forma de modelar isso é usando o conceito de n-grams.\n",
        "## Exemplo ##\n",
        "# Na frase: “Eu não gosto desse governo”, na modelagem inicial, passamos para o modelo cada palavra sendo uma feature, ficaria\n",
        "# a) {eu, não, gosto, desse, governo}\n",
        "# Usando Bigrams, passaríamos para o modelo 2 palavras, veja:\n",
        "# b) {eu não, não gosto, gosto desse, desse governo}\n",
        "\n",
        "## Ou seja, estamos dizendo que uma palavra tem alguma relação com outra palavra que vem logo a seguir. Lembra a história da independência de termos?\n",
        "\n",
        "## Para implementar o bigrama basta usar o parâmetro ngram_range a seguir.\n",
        "## A documentação da função CountVectorizer diz o seguinte:\n",
        "# For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "cce3b99b",
      "metadata": {
        "id": "cce3b99b"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "freq_tweets = vectorizer.fit_transform(tweets)\n",
        "modelo = MultinomialNB()\n",
        "modelo.fit(freq_tweets,classes)\n",
        "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "886f2f40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "886f2f40",
        "outputId": "b273ed53-2e25-4629-e4fa-283fbf4374ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8991340407366752"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "metrics.accuracy_score(classes,resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "03d55b1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03d55b1a",
        "outputId": "47c780af-6455-4de9-98b8-f96cce00762c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativo       0.90      0.93      0.92      2446\n",
            "      Neutro       0.82      0.89      0.85      2453\n",
            "    Positivo       0.97      0.88      0.92      3300\n",
            "\n",
            "    accuracy                           0.90      8199\n",
            "   macro avg       0.90      0.90      0.90      8199\n",
            "weighted avg       0.90      0.90      0.90      8199\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(metrics.classification_report(classes,resultados))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "a7b04790",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7b04790",
        "outputId": "ca8f8ee1-ee57-4a6d-e5f7-0a2687c84d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predito   Negativo  Neutro  Positivo   All\n",
            "Real                                      \n",
            "Negativo      2285     157         4  2446\n",
            "Neutro         188    2175        90  2453\n",
            "Positivo        62     326      2912  3300\n",
            "All           2535    2658      3006  8199\n"
          ]
        }
      ],
      "source": [
        "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "85317714",
      "metadata": {
        "id": "85317714"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}